{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thrown-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-breeding",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "obvious-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['target', 'feature1', 'feature2', 'feature3', 'feature4', \n",
    "                'feature5', 'feature6', 'feature7', 'feature8', 'feature9', 'feature10', \n",
    "                'feature11', 'feature12', 'feature13', 'feature14', 'feature15', 'feature16']\n",
    "\n",
    "## df_adult = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names = column_names, index_col = False)\n",
    "df_letter = pd.read_csv('letter-recognition.data', names = column_names, index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "native-option",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0      T         2         8         3         5         1         8   \n",
       "1      I         5        12         3         7         2        10   \n",
       "2      D         4        11         6         8         6        10   \n",
       "3      N         7        11         6         6         3         5   \n",
       "4      G         2         1         3         1         1         8   \n",
       "\n",
       "   feature7  feature8  feature9  feature10  feature11  feature12  feature13  \\\n",
       "0        13         0         6          6         10          8          0   \n",
       "1         5         5         4         13          3          9          2   \n",
       "2         6         2         6         10          3          7          3   \n",
       "3         9         4         6          4          4         10          6   \n",
       "4         6         6         6          6          5          9          1   \n",
       "\n",
       "   feature14  feature15  feature16  \n",
       "0          8          0          8  \n",
       "1          8          4         10  \n",
       "2          7          3          9  \n",
       "3         10          2          8  \n",
       "4          7          5         10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_letter.shape)\n",
    "df_letter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "shaped-nitrogen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         2         8         3         5         1         8        13   \n",
       "1         5        12         3         7         2        10         5   \n",
       "2         4        11         6         8         6        10         6   \n",
       "3         7        11         6         6         3         5         9   \n",
       "4         2         1         3         1         1         8         6   \n",
       "\n",
       "   feature8  feature9  feature10  feature11  feature12  feature13  feature14  \\\n",
       "0         0         6          6         10          8          0          8   \n",
       "1         5         4         13          3          9          2          8   \n",
       "2         2         6         10          3          7          3          7   \n",
       "3         4         6          4          4         10          6         10   \n",
       "4         6         6          6          5          9          1          7   \n",
       "\n",
       "   feature15  feature16  \n",
       "0          0          8  \n",
       "1          4         10  \n",
       "2          3          9  \n",
       "3          2          8  \n",
       "4          5         10  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_letter.iloc[:, 1:]\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "innocent-catholic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = StandardScaler().fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "minus-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_replace_1 (letter):\n",
    "    df_letter.loc[df_letter['target'] == letter, ['target']] = 1\n",
    "    \n",
    "def letter_replace_0 (letter):\n",
    "    df_letter.loc[df_letter['target'] == letter, ['target']] = 0\n",
    "\n",
    "positive_letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M'] \n",
    "negative_letters = ['N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "for i in positive_letters:\n",
    "    letter_replace_1(i)\n",
    "\n",
    "for i in negative_letters:\n",
    "    letter_replace_0(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "technological-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     20000\n",
       "unique        2\n",
       "top           0\n",
       "freq      10060\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_letter['target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "synthetic-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_letter.loc[:, ['target']]\n",
    "Y = Y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "alike-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat training and testing data sets for 5 trials\n",
    "X_train_arr = []\n",
    "X_test_arr = []\n",
    "Y_train_arr = []\n",
    "Y_test_arr = []\n",
    "\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split( \n",
    "        X, Y, train_size = 5000, stratify = Y, \n",
    "        shuffle = True, random_state = i)\n",
    "    X_train_arr.append(X_train)\n",
    "    X_test_arr.append(X_test)\n",
    "    Y_train_arr.append(Y_train)\n",
    "    Y_test_arr.append(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "painful-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0, 1, 2, 3, 4]:\n",
    "    Y_train_arr[i] = Y_train_arr[i].values.ravel()\n",
    "    Y_test_arr[i] = Y_test_arr[i].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-nickname",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sufficient-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_list for SVM.\n",
    "C_logre = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, \n",
    "         1e1, 1e2, 1e3, 1e4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "handled-supplement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##pipe = Pipeline(steps=[('std', StandardScaler()), ('logRe', LogisticRegression())])\n",
    "pipe = Pipeline([('logRe', LogisticRegression())])\n",
    "\n",
    "search_space = [{'logRe': [LogisticRegression(max_iter = 5000)],\n",
    "                 'logRe__solver': ['saga'],\n",
    "                 'logRe__penalty': ['l1', 'l2'],\n",
    "                 'logRe__C': C_logre},\n",
    "                {'logRe': [LogisticRegression(max_iter = 5000)],\n",
    "                 'logRe__solver': ['lbfgs', 'sag', 'newton-cg'],\n",
    "                 'logRe__penalty': ['l2'],\n",
    "                 'logRe__C': C_logre},\n",
    "                {'logRe': [LogisticRegression(max_iter = 5000)],\n",
    "                 'logRe__solver': ['saga', 'lbfgs', 'sag', 'newton-cg'],\n",
    "                 'logRe__penalty': ['none']}\n",
    "                ]\n",
    "\n",
    "search = GridSearchCV(pipe, search_space, cv = StratifiedKFold(n_splits=5), \n",
    "                   scoring = ['accuracy', 'roc_auc', 'f1'], refit = False,\n",
    "                   verbose = 0, n_jobs = -1)\n",
    "\n",
    "best_logre_arr = []\n",
    "\n",
    "#search training set in stratified 5-fold manner cross 5 trials, and store the best models in best_logre_arr\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    best_logre = search.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    best_logre_arr.append(best_logre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "correct-insured",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 0.1, 'logRe__penalty': 'l2', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10000.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      " \n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 0.1, 'logRe__penalty': 'l2', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10000.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      " \n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 0.1, 'logRe__penalty': 'l2', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10000.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      " \n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 0.1, 'logRe__penalty': 'l2', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10000.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      " \n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 0.1, 'logRe__penalty': 'l2', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10000.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#show the result of best models\n",
    "#each group of three is the result for a trial\n",
    "#within each group, each result is the best model for each performance metric\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    print(best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_accuracy'])])\n",
    "    print(best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_roc_auc'])])\n",
    "    print(best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_f1'])])\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-mumbai",
   "metadata": {},
   "source": [
    "## acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "explicit-interstate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7246\n",
      "0.7266666666666667\n",
      "0.7266\n",
      "0.7243333333333334\n",
      "0.7298\n",
      "0.7235333333333334\n",
      "0.7188\n",
      "0.7296\n",
      "0.7194\n",
      "0.7281333333333333\n",
      "[0.7246, 0.7266, 0.7298, 0.7188, 0.7194]\n",
      "[0.7266666666666667, 0.7243333333333334, 0.7235333333333334, 0.7296, 0.7281333333333333]\n"
     ]
    }
   ],
   "source": [
    "# logre_lam_acc_train \n",
    "# logre_lam_acc_test \n",
    "logre_lam_acc_train = []\n",
    "logre_lam_acc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    logre = LogisticRegression(max_iter = 5000, \n",
    "                               C = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_accuracy'])].get('logRe__C'),\n",
    "                               penalty = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_accuracy'])].get('logRe__penalty'),\n",
    "                               solver = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_accuracy'])].get('logRe__solver')\n",
    "                              )\n",
    "    logre.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_acc = accuracy_score(Y_train_arr[i], logre.predict(X_train_arr[i]))\n",
    "    test_acc = accuracy_score(Y_test_arr[i], logre.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_acc)\n",
    "    print(test_acc)\n",
    "    \n",
    "    logre_lam_acc_train.append(train_acc)\n",
    "    logre_lam_acc_test.append(test_acc)\n",
    "    \n",
    "print(logre_lam_acc_train)\n",
    "print(logre_lam_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "honey-passage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72384\n",
      "0.7264533333333334\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "logre_lam_acc_train_mean = sum(logre_lam_acc_train)/len(logre_lam_acc_train)\n",
    "logre_lam_acc_test_mean = sum(logre_lam_acc_test)/len(logre_lam_acc_test)\n",
    "print(logre_lam_acc_train_mean)\n",
    "print(logre_lam_acc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-railway",
   "metadata": {},
   "source": [
    "## roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "completed-bridges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7250657023652851\n",
      "0.7282747512243775\n",
      "0.725041701501254\n",
      "0.7250895698911826\n",
      "0.7322587613154075\n",
      "0.7257459935224335\n",
      "0.7187158737714558\n",
      "0.7305422995227827\n",
      "0.7202535291270484\n",
      "0.7297040026774297\n",
      "[0.7250657023652851, 0.725041701501254, 0.7322587613154075, 0.7187158737714558, 0.7202535291270484]\n",
      "[0.7282747512243775, 0.7250895698911826, 0.7257459935224335, 0.7305422995227827, 0.7297040026774297]\n"
     ]
    }
   ],
   "source": [
    "# logre_lam_roc_train stores\n",
    "# logre_lam_roc_test stores\n",
    "logre_lam_roc_train = []\n",
    "logre_lam_roc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    logre = LogisticRegression(max_iter = 5000, \n",
    "                               C = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_roc_auc'])].get('logRe__C'),\n",
    "                               penalty = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_roc_auc'])].get('logRe__penalty'),\n",
    "                               solver = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_roc_auc'])].get('logRe__solver')\n",
    "                              )\n",
    "    logre.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_roc = roc_auc_score(Y_train_arr[i], logre.predict(X_train_arr[i]))\n",
    "    test_roc = roc_auc_score(Y_test_arr[i], logre.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_roc)\n",
    "    print(test_roc)\n",
    "    \n",
    "    logre_lam_roc_train.append(train_roc)\n",
    "    logre_lam_roc_test.append(test_roc)\n",
    "    \n",
    "print(logre_lam_roc_train)\n",
    "print(logre_lam_roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eleven-brave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7242671136160901\n",
      "0.7278713233676413\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "logre_lam_roc_train_mean = sum(logre_lam_roc_train)/len(logre_lam_roc_train)\n",
    "logre_lam_roc_test_mean = sum(logre_lam_roc_test)/len(logre_lam_roc_test)\n",
    "print(logre_lam_roc_train_mean)\n",
    "print(logre_lam_roc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-referral",
   "metadata": {},
   "source": [
    "## f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "massive-interference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7270560190703218\n",
      "0.7333856619570904\n",
      "0.7257131458208658\n",
      "0.7247014875592022\n",
      "0.733134328358209\n",
      "0.7280777109627965\n",
      "0.7227586206896552\n",
      "0.7355961022823883\n",
      "0.7213375796178343\n",
      "0.7358551989061787\n",
      "[0.7270560190703218, 0.7257131458208658, 0.733134328358209, 0.7227586206896552, 0.7213375796178343]\n",
      "[0.7333856619570904, 0.7247014875592022, 0.7280777109627965, 0.7355961022823883, 0.7358551989061787]\n"
     ]
    }
   ],
   "source": [
    "# logre_lam_f1_train stores\n",
    "# logre_lam_f1_test stores\n",
    "logre_lam_f1_train = []\n",
    "logre_lam_f1_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    logre = LogisticRegression(max_iter = 5000, \n",
    "                               C = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_f1'])].get('logRe__C'),\n",
    "                               penalty = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_f1'])].get('logRe__penalty'),\n",
    "                               solver = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_f1'])].get('logRe__solver')\n",
    "                              )\n",
    "    logre.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_f1 = f1_score(Y_train_arr[i], logre.predict(X_train_arr[i]))\n",
    "    test_f1 = f1_score(Y_test_arr[i], logre.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_f1)\n",
    "    print(test_f1)\n",
    "    \n",
    "    logre_lam_f1_train.append(train_f1)\n",
    "    logre_lam_f1_test.append(test_f1)\n",
    "    \n",
    "print(logre_lam_f1_train)\n",
    "print(logre_lam_f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "invisible-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7259999387113771\n",
      "0.7315232323335312\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "logre_lam_f1_train_mean = sum(logre_lam_f1_train)/len(logre_lam_f1_train)\n",
    "logre_lam_f1_test_mean = sum(logre_lam_f1_test)/len(logre_lam_f1_test)\n",
    "print(logre_lam_f1_train_mean)\n",
    "print(logre_lam_f1_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-substance",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "swiss-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C list for SVM\n",
    "C_svm = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]\n",
    "C_svm_linear = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1]\n",
    "\n",
    "# gamma list for SVM with kernel rbf\n",
    "gamma_svm = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rolled-familiar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##pipe = Pipeline(steps=[('std', StandardScaler()), ('svm_classifier', svm.SVC())])\n",
    "pipe = Pipeline([('svm_classifier', svm.SVC())])\n",
    "\n",
    "search_space = [{'svm_classifier': [svm.SVC()],\n",
    "                 'svm_classifier__kernel': ['linear'],\n",
    "                 'svm_classifier__C': C_svm_linear},\n",
    "                {'svm_classifier': [svm.SVC(max_iter = 1000000)],\n",
    "                 'svm_classifier__kernel': ['linear'],\n",
    "                 'svm_classifier__C': [100, 1000]},\n",
    "                {'svm_classifier': [svm.SVC()],\n",
    "                 'svm_classifier__kernel': ['poly'],\n",
    "                 'svm_classifier__degree': [2, 3],\n",
    "                 'svm_classifier__C': C_svm},\n",
    "                {'svm_classifier': [svm.SVC()],\n",
    "                 'svm_classifier__kernel': ['rbf'],\n",
    "                 'svm_classifier__gamma': gamma_svm,\n",
    "                 'svm_classifier__C': C_svm}\n",
    "                ]\n",
    "\n",
    "clf = GridSearchCV(pipe, search_space, cv = StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc', 'f1'], refit=False,\n",
    "                   verbose=0, n_jobs = -1)\n",
    "\n",
    "best_svm_arr = []\n",
    "\n",
    "#search training set in stratified 5-fold manner cross 5 trials, and store the best models in best_svm_arr\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    best_svm = clf.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    best_svm_arr.append(best_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "needed-candidate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      " \n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      " \n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      " \n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      " \n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.5, 'svm_classifier__kernel': 'rbf'}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#show the result of best models\n",
    "#each group of three is the result for a trial\n",
    "#within each group, each result is the best model for each performance metric\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    print(best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])])\n",
    "    print(best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])])\n",
    "    print(best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])])\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-cocktail",
   "metadata": {},
   "source": [
    "## acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "british-agenda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9606\n",
      "1.0\n",
      "0.9609333333333333\n",
      "1.0\n",
      "0.9610666666666666\n",
      "1.0\n",
      "0.9652\n",
      "1.0\n",
      "0.9641333333333333\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9606, 0.9609333333333333, 0.9610666666666666, 0.9652, 0.9641333333333333]\n"
     ]
    }
   ],
   "source": [
    "# svm_lam_acc_train stores\n",
    "# svm_lam_acc_test stores\n",
    "svm_lam_acc_train = []\n",
    "svm_lam_acc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    if best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__kernel') == 'poly':\n",
    "        svm_cls = svm.SVC(kernel = 'poly',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__C'),\n",
    "                          degree = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__degree')\n",
    "                         )\n",
    "    elif best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__kernel') == 'linear':\n",
    "        svm_cls = svm.SVC(kernel = 'linear',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__C')\n",
    "                         )\n",
    "    else:\n",
    "        svm_cls = svm.SVC(kernel = 'rbf', \n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__C'),\n",
    "                          gamma = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__gamma')\n",
    "                         )\n",
    "    \n",
    "    svm_cls.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_acc = accuracy_score(Y_train_arr[i], svm_cls.predict(X_train_arr[i]))\n",
    "    test_acc = accuracy_score(Y_test_arr[i], svm_cls.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_acc)\n",
    "    print(test_acc)\n",
    "    \n",
    "    svm_lam_acc_train.append(train_acc)\n",
    "    svm_lam_acc_test.append(test_acc)\n",
    "    \n",
    "print(svm_lam_acc_train)\n",
    "print(svm_lam_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "absent-place",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9623866666666666\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "svm_lam_acc_train_mean = sum(svm_lam_acc_train)/len(svm_lam_acc_train)\n",
    "svm_lam_acc_test_mean = sum(svm_lam_acc_test)/len(svm_lam_acc_test)\n",
    "print(svm_lam_acc_train_mean)\n",
    "print(svm_lam_acc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-canberra",
   "metadata": {},
   "source": [
    "## roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fiscal-transmission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9605837810161165\n",
      "1.0\n",
      "0.9608679245786181\n",
      "1.0\n",
      "0.9610332638641658\n",
      "1.0\n",
      "0.9651963470684943\n",
      "1.0\n",
      "0.964120041654833\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9605837810161165, 0.9608679245786181, 0.9610332638641658, 0.9651963470684943, 0.964120041654833]\n"
     ]
    }
   ],
   "source": [
    "# svm_lam_roc_train stores\n",
    "# svm_lam_roc_test stores\n",
    "svm_lam_roc_train = []\n",
    "svm_lam_roc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    if best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__kernel') == 'poly':\n",
    "        svm_cls = svm.SVC(kernel = 'poly',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__C'),\n",
    "                          degree = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__degree')\n",
    "                         )\n",
    "    elif best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__kernel') == 'linear':\n",
    "        svm_cls = svm.SVC(kernel = 'linear',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__C')\n",
    "                         )\n",
    "    else:\n",
    "        svm_cls = svm.SVC(kernel = 'rbf', \n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__C'),\n",
    "                          gamma = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__gamma')\n",
    "                         )\n",
    "    \n",
    "    svm_cls.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_roc = roc_auc_score(Y_train_arr[i], svm_cls.predict(X_train_arr[i]))\n",
    "    test_roc = roc_auc_score(Y_test_arr[i], svm_cls.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_roc)\n",
    "    print(test_roc)\n",
    "    \n",
    "    svm_lam_roc_train.append(train_roc)\n",
    "    svm_lam_roc_test.append(test_roc)\n",
    "    \n",
    "print(svm_lam_roc_train)\n",
    "print(svm_lam_roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "administrative-operation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9623602716364456\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "svm_lam_roc_train_mean = sum(svm_lam_roc_train)/len(svm_lam_roc_train)\n",
    "svm_lam_roc_test_mean = sum(svm_lam_roc_test)/len(svm_lam_roc_test)\n",
    "print(svm_lam_roc_train_mean)\n",
    "print(svm_lam_roc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-worthy",
   "metadata": {},
   "source": [
    "## f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "legendary-summit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9602635648490553\n",
      "1.0\n",
      "0.9602711864406779\n",
      "1.0\n",
      "0.9606203641267701\n",
      "1.0\n",
      "0.964975845410628\n",
      "1.0\n",
      "0.9638440860215054\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9602635648490553, 0.9602711864406779, 0.9606203641267701, 0.964975845410628, 0.9638440860215054]\n"
     ]
    }
   ],
   "source": [
    "# svm_lam_f1_train stores\n",
    "# svm_lam_f1_test stores\n",
    "svm_lam_f1_train = []\n",
    "svm_lam_f1_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    if best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__kernel') == 'poly':\n",
    "        svm_cls = svm.SVC(kernel = 'poly',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__C'),\n",
    "                          degree = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__degree')\n",
    "                         )\n",
    "    elif best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__kernel') == 'linear':\n",
    "        svm_cls = svm.SVC(kernel = 'linear',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__C')\n",
    "                         )\n",
    "    else:\n",
    "        svm_cls = svm.SVC(kernel = 'rbf', \n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__C'),\n",
    "                          gamma = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__gamma')\n",
    "                         )\n",
    "    \n",
    "    svm_cls.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_f1 = f1_score(Y_train_arr[i], svm_cls.predict(X_train_arr[i]))\n",
    "    test_f1 = f1_score(Y_test_arr[i], svm_cls.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_f1)\n",
    "    print(test_f1)\n",
    "    \n",
    "    svm_lam_f1_train.append(train_f1)\n",
    "    svm_lam_f1_test.append(test_f1)\n",
    "    \n",
    "print(svm_lam_f1_train)\n",
    "print(svm_lam_f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "manufactured-calibration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9619950093697274\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "svm_lam_f1_train_mean = sum(svm_lam_f1_train)/len(svm_lam_f1_train)\n",
    "svm_lam_f1_test_mean = sum(svm_lam_f1_test)/len(svm_lam_f1_test)\n",
    "print(svm_lam_f1_train_mean)\n",
    "print(svm_lam_f1_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-consolidation",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "later-converter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   5,   9,  13,  17,  21,  25,  29,  33,  37,  41,  45,  49,\n",
       "        53,  57,  61,  65,  69,  73,  77,  81,  85,  89,  93,  97, 101])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K list for KNN\n",
    "K_knn = np.arange(1, 105, 4)\n",
    "K_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adopted-timing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##pipe = Pipeline(steps=[('std', StandardScaler()), ('knn', KNeighborsClassifier())])\n",
    "pipe = Pipeline([('knn', KNeighborsClassifier())])\n",
    "\n",
    "search_space = [{'knn': [KNeighborsClassifier()],\n",
    "                 'knn__weights': ['uniform', 'distance'],\n",
    "                 'knn__n_neighbors': K_knn}\n",
    "                ]\n",
    "\n",
    "search = GridSearchCV(pipe, search_space, cv = StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc', 'f1'], refit=False,\n",
    "                   verbose=0, n_jobs = -1)\n",
    "\n",
    "best_knn_arr = []\n",
    "\n",
    "#search training set in stratified 5-fold manner cross 5 trials, and store the best models in best_svm_arr\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    best_knn = search.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    best_knn_arr.append(best_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adjusted-cheese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 1, 'knn__weights': 'uniform'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 1, 'knn__weights': 'uniform'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 1, 'knn__weights': 'uniform'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 1, 'knn__weights': 'uniform'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 1, 'knn__weights': 'uniform'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 1, 'knn__weights': 'uniform'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 1, 'knn__weights': 'uniform'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 1, 'knn__weights': 'uniform'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 1, 'knn__weights': 'uniform'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 1, 'knn__weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "#show the result of best models\n",
    "#each group of three is the result for a trial\n",
    "#within each group, each result is the best model for each performance metric\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    print(best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_accuracy'])])\n",
    "    print(best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_roc_auc'])])\n",
    "    print(best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_f1'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-polls",
   "metadata": {},
   "source": [
    "## acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "immune-dubai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9528\n",
      "1.0\n",
      "0.9511333333333334\n",
      "1.0\n",
      "0.9516\n",
      "1.0\n",
      "0.9536666666666667\n",
      "1.0\n",
      "0.9572\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9528, 0.9511333333333334, 0.9516, 0.9536666666666667, 0.9572]\n"
     ]
    }
   ],
   "source": [
    "# knn_lam_acc_train stores\n",
    "# knn_lam_acc_test stores\n",
    "knn_lam_acc_train = []\n",
    "knn_lam_acc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    knn = KNeighborsClassifier(weights = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_accuracy'])].get('knn__weights'),\n",
    "                               n_neighbors = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_accuracy'])].get('knn__n_neighbors')\n",
    "                              )\n",
    "    \n",
    "    knn.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_acc = accuracy_score(Y_train_arr[i], knn.predict(X_train_arr[i]))\n",
    "    test_acc = accuracy_score(Y_test_arr[i], knn.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_acc)\n",
    "    print(test_acc)\n",
    "    \n",
    "    knn_lam_acc_train.append(train_acc)\n",
    "    knn_lam_acc_test.append(test_acc)\n",
    "    \n",
    "print(knn_lam_acc_train)\n",
    "print(knn_lam_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "south-eagle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.95328\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "knn_lam_acc_train_mean = sum(knn_lam_acc_train)/len(knn_lam_acc_train)\n",
    "knn_lam_acc_test_mean = sum(knn_lam_acc_test)/len(knn_lam_acc_test)\n",
    "print(knn_lam_acc_train_mean)\n",
    "print(knn_lam_acc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-bumper",
   "metadata": {},
   "source": [
    "## roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "similar-imperial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9483598742888079\n",
      "1.0\n",
      "0.945835116730869\n",
      "1.0\n",
      "0.9440546526341614\n",
      "1.0\n",
      "0.9467007478935908\n",
      "1.0\n",
      "0.9491511027730333\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9483598742888079, 0.945835116730869, 0.9440546526341614, 0.9467007478935908, 0.9491511027730333]\n"
     ]
    }
   ],
   "source": [
    "# knn_lam_roc_train stores\n",
    "# knn_lam_roc_test stores\n",
    "knn_lam_roc_train = []\n",
    "knn_lam_roc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    knn = KNeighborsClassifier(weights = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_roc_auc'])].get('knn__weights'),\n",
    "                               n_neighbors = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_roc_auc'])].get('knn__n_neighbors')\n",
    "                              )\n",
    "    knn.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_roc = roc_auc_score(Y_train_arr[i], knn.predict(X_train_arr[i]))\n",
    "    test_roc = roc_auc_score(Y_test_arr[i], knn.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_roc)\n",
    "    print(test_roc)\n",
    "    \n",
    "    knn_lam_roc_train.append(train_roc)\n",
    "    knn_lam_roc_test.append(test_roc)\n",
    "    \n",
    "print(knn_lam_roc_train)\n",
    "print(knn_lam_roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "renewable-constant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9468202988640926\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "knn_lam_roc_train_mean = sum(knn_lam_roc_train)/len(knn_lam_roc_train)\n",
    "knn_lam_roc_test_mean = sum(knn_lam_roc_test)/len(knn_lam_roc_test)\n",
    "print(knn_lam_roc_train_mean)\n",
    "print(knn_lam_roc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-empty",
   "metadata": {},
   "source": [
    "## f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "lined-seller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9524257492272543\n",
      "1.0\n",
      "0.9506231054227012\n",
      "1.0\n",
      "0.95114401076716\n",
      "1.0\n",
      "0.9534400750318215\n",
      "1.0\n",
      "0.9569820423478961\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9524257492272543, 0.9506231054227012, 0.95114401076716, 0.9534400750318215, 0.9569820423478961]\n"
     ]
    }
   ],
   "source": [
    "# knn_lam_f1_train stores\n",
    "# knn_lam_f1_test stores\n",
    "knn_lam_f1_train = []\n",
    "knn_lam_f1_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    knn = KNeighborsClassifier(weights = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_f1'])].get('knn__weights'),\n",
    "                               n_neighbors = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_f1'])].get('knn__n_neighbors')\n",
    "                              )\n",
    "    knn.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_f1 = f1_score(Y_train_arr[i], knn.predict(X_train_arr[i]))\n",
    "    test_f1 = f1_score(Y_test_arr[i], knn.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_f1)\n",
    "    print(test_f1)\n",
    "    \n",
    "    knn_lam_f1_train.append(train_f1)\n",
    "    knn_lam_f1_test.append(test_f1)\n",
    "    \n",
    "print(knn_lam_f1_train)\n",
    "print(knn_lam_f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fancy-teddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9529229965593666\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "knn_lam_f1_train_mean = sum(knn_lam_f1_train)/len(knn_lam_f1_train)\n",
    "knn_lam_f1_test_mean = sum(knn_lam_f1_test)/len(knn_lam_f1_test)\n",
    "print(knn_lam_f1_train_mean)\n",
    "print(knn_lam_f1_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-helicopter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
