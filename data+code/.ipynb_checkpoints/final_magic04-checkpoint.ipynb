{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thrown-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-sarah",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "obvious-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = np.arange(0, 11, 1)\n",
    "\n",
    "df_magic04 = pd.read_csv('magic04.data', names = column_names, index_col = False, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "native-option",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19015</th>\n",
       "      <td>21.3846</td>\n",
       "      <td>10.9170</td>\n",
       "      <td>2.6161</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>15.2618</td>\n",
       "      <td>11.5245</td>\n",
       "      <td>2.8766</td>\n",
       "      <td>2.4229</td>\n",
       "      <td>106.8258</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19016</th>\n",
       "      <td>28.9452</td>\n",
       "      <td>6.7020</td>\n",
       "      <td>2.2672</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>37.0816</td>\n",
       "      <td>13.1853</td>\n",
       "      <td>-2.9632</td>\n",
       "      <td>86.7975</td>\n",
       "      <td>247.4560</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19017</th>\n",
       "      <td>75.4455</td>\n",
       "      <td>47.5305</td>\n",
       "      <td>3.4483</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>-9.3561</td>\n",
       "      <td>41.0562</td>\n",
       "      <td>-9.4662</td>\n",
       "      <td>30.2987</td>\n",
       "      <td>256.5166</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>120.5135</td>\n",
       "      <td>76.9018</td>\n",
       "      <td>3.9939</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>5.8043</td>\n",
       "      <td>-93.5224</td>\n",
       "      <td>-63.8389</td>\n",
       "      <td>84.6874</td>\n",
       "      <td>408.3166</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19019</th>\n",
       "      <td>187.1814</td>\n",
       "      <td>53.0014</td>\n",
       "      <td>3.2093</td>\n",
       "      <td>0.2876</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>-167.3125</td>\n",
       "      <td>-168.4558</td>\n",
       "      <td>31.4755</td>\n",
       "      <td>52.7310</td>\n",
       "      <td>272.3174</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19020 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1       2       3       4         5         6   \\\n",
       "0       28.7967   16.0021  2.6449  0.3918  0.1982   27.7004   22.0110   \n",
       "1       31.6036   11.7235  2.5185  0.5303  0.3773   26.2722   23.8238   \n",
       "2      162.0520  136.0310  4.0612  0.0374  0.0187  116.7410  -64.8580   \n",
       "3       23.8172    9.5728  2.3385  0.6147  0.3922   27.2107   -6.4633   \n",
       "4       75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277   28.5525   \n",
       "...         ...       ...     ...     ...     ...       ...       ...   \n",
       "19015   21.3846   10.9170  2.6161  0.5857  0.3934   15.2618   11.5245   \n",
       "19016   28.9452    6.7020  2.2672  0.5351  0.2784   37.0816   13.1853   \n",
       "19017   75.4455   47.5305  3.4483  0.1417  0.0549   -9.3561   41.0562   \n",
       "19018  120.5135   76.9018  3.9939  0.0944  0.0683    5.8043  -93.5224   \n",
       "19019  187.1814   53.0014  3.2093  0.2876  0.1539 -167.3125 -168.4558   \n",
       "\n",
       "            7        8         9  10  \n",
       "0      -8.2027  40.0920   81.8828  g  \n",
       "1      -9.9574   6.3609  205.2610  g  \n",
       "2     -45.2160  76.9600  256.7880  g  \n",
       "3      -7.1513  10.4490  116.7370  g  \n",
       "4      21.8393   4.6480  356.4620  g  \n",
       "...        ...      ...       ... ..  \n",
       "19015   2.8766   2.4229  106.8258  h  \n",
       "19016  -2.9632  86.7975  247.4560  h  \n",
       "19017  -9.4662  30.2987  256.5166  h  \n",
       "19018 -63.8389  84.6874  408.3166  h  \n",
       "19019  31.4755  52.7310  272.3174  h  \n",
       "\n",
       "[19020 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_magic04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "shaped-nitrogen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19020, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19015</th>\n",
       "      <td>21.3846</td>\n",
       "      <td>10.9170</td>\n",
       "      <td>2.6161</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>15.2618</td>\n",
       "      <td>11.5245</td>\n",
       "      <td>2.8766</td>\n",
       "      <td>2.4229</td>\n",
       "      <td>106.8258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19016</th>\n",
       "      <td>28.9452</td>\n",
       "      <td>6.7020</td>\n",
       "      <td>2.2672</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>37.0816</td>\n",
       "      <td>13.1853</td>\n",
       "      <td>-2.9632</td>\n",
       "      <td>86.7975</td>\n",
       "      <td>247.4560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19017</th>\n",
       "      <td>75.4455</td>\n",
       "      <td>47.5305</td>\n",
       "      <td>3.4483</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>-9.3561</td>\n",
       "      <td>41.0562</td>\n",
       "      <td>-9.4662</td>\n",
       "      <td>30.2987</td>\n",
       "      <td>256.5166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>120.5135</td>\n",
       "      <td>76.9018</td>\n",
       "      <td>3.9939</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>5.8043</td>\n",
       "      <td>-93.5224</td>\n",
       "      <td>-63.8389</td>\n",
       "      <td>84.6874</td>\n",
       "      <td>408.3166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19019</th>\n",
       "      <td>187.1814</td>\n",
       "      <td>53.0014</td>\n",
       "      <td>3.2093</td>\n",
       "      <td>0.2876</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>-167.3125</td>\n",
       "      <td>-168.4558</td>\n",
       "      <td>31.4755</td>\n",
       "      <td>52.7310</td>\n",
       "      <td>272.3174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19020 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1       2       3       4         5         6  \\\n",
       "0       28.7967   16.0021  2.6449  0.3918  0.1982   27.7004   22.0110   \n",
       "1       31.6036   11.7235  2.5185  0.5303  0.3773   26.2722   23.8238   \n",
       "2      162.0520  136.0310  4.0612  0.0374  0.0187  116.7410  -64.8580   \n",
       "3       23.8172    9.5728  2.3385  0.6147  0.3922   27.2107   -6.4633   \n",
       "4       75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277   28.5525   \n",
       "...         ...       ...     ...     ...     ...       ...       ...   \n",
       "19015   21.3846   10.9170  2.6161  0.5857  0.3934   15.2618   11.5245   \n",
       "19016   28.9452    6.7020  2.2672  0.5351  0.2784   37.0816   13.1853   \n",
       "19017   75.4455   47.5305  3.4483  0.1417  0.0549   -9.3561   41.0562   \n",
       "19018  120.5135   76.9018  3.9939  0.0944  0.0683    5.8043  -93.5224   \n",
       "19019  187.1814   53.0014  3.2093  0.2876  0.1539 -167.3125 -168.4558   \n",
       "\n",
       "             7        8         9  \n",
       "0      -8.2027  40.0920   81.8828  \n",
       "1      -9.9574   6.3609  205.2610  \n",
       "2     -45.2160  76.9600  256.7880  \n",
       "3      -7.1513  10.4490  116.7370  \n",
       "4      21.8393   4.6480  356.4620  \n",
       "...        ...      ...       ...  \n",
       "19015   2.8766   2.4229  106.8258  \n",
       "19016  -2.9632  86.7975  247.4560  \n",
       "19017  -9.4662  30.2987  256.5166  \n",
       "19018 -63.8389  84.6874  408.3166  \n",
       "19019  31.4755  52.7310  272.3174  \n",
       "\n",
       "[19020 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_magic04.iloc[:, :10]\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ranking-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "minus-pride",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([ 6688, 12332], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df_magic04.loc[:, [10]]\n",
    "Y = Y.replace('g', 1)\n",
    "Y = Y.replace('h', 0)\n",
    "np.unique(Y, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alike-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat training and testing data sets for 5 trials\n",
    "X_train_arr = []\n",
    "X_test_arr = []\n",
    "Y_train_arr = []\n",
    "Y_test_arr = []\n",
    "\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split( \n",
    "        X, Y, train_size = 5000, stratify = Y, \n",
    "        shuffle = True, random_state = i)\n",
    "    X_train_arr.append(X_train)\n",
    "    X_test_arr.append(X_test)\n",
    "    Y_train_arr.append(Y_train)\n",
    "    Y_test_arr.append(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "painful-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0, 1, 2, 3, 4]:\n",
    "    Y_train_arr[i] = Y_train_arr[i].values.ravel()\n",
    "    Y_test_arr[i] = Y_test_arr[i].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-nickname",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sufficient-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_list for SVM.\n",
    "C_logre = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, \n",
    "         1e1, 1e2, 1e3, 1e4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "handled-supplement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([('logRe', LogisticRegression())])\n",
    "\n",
    "search_space = [{'logRe': [LogisticRegression(max_iter = 5000)],\n",
    "                 'logRe__solver': ['saga'],\n",
    "                 'logRe__penalty': ['l1', 'l2'],\n",
    "                 'logRe__C': C_logre},\n",
    "                {'logRe': [LogisticRegression(max_iter = 5000)],\n",
    "                 'logRe__solver': ['lbfgs', 'sag', 'newton-cg'],\n",
    "                 'logRe__penalty': ['l2'],\n",
    "                 'logRe__C': C_logre},\n",
    "                {'logRe': [LogisticRegression(max_iter = 5000)],\n",
    "                 'logRe__solver': ['saga', 'lbfgs', 'sag', 'newton-cg'],\n",
    "                 'logRe__penalty': ['none']}\n",
    "                ]\n",
    "\n",
    "search = GridSearchCV(pipe, search_space, cv = StratifiedKFold(n_splits=5), \n",
    "                   scoring = ['accuracy', 'roc_auc', 'f1'], refit = False,\n",
    "                   verbose = 0, n_jobs = -1)\n",
    "\n",
    "best_logre_arr = []\n",
    "\n",
    "#search training set in stratified 5-fold manner cross 5 trials, and store the best models in best_logre_arr\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    best_logre = search.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    best_logre_arr.append(best_logre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "correct-insured",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      " \n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      " \n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      " \n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      " \n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 1.0, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#show the result of best models\n",
    "#each group of three is the result for a trial\n",
    "#within each group, each result is the best model for each performance metric\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    print(best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_accuracy'])])\n",
    "    print(best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_roc_auc'])])\n",
    "    print(best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_f1'])])\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-mumbai",
   "metadata": {},
   "source": [
    "## acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "explicit-interstate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7926\n",
      "0.7914407988587732\n",
      "0.794\n",
      "0.792867332382311\n",
      "0.7868\n",
      "0.793509272467903\n",
      "0.7888\n",
      "0.7927246790299572\n",
      "0.8042\n",
      "0.7868045649072754\n",
      "[0.7926, 0.794, 0.7868, 0.7888, 0.8042]\n",
      "[0.7914407988587732, 0.792867332382311, 0.793509272467903, 0.7927246790299572, 0.7868045649072754]\n"
     ]
    }
   ],
   "source": [
    "# logre_lam_acc_train \n",
    "# logre_lam_acc_test \n",
    "logre_lam_acc_train = []\n",
    "logre_lam_acc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    logre = LogisticRegression(max_iter = 5000, \n",
    "                               C = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_accuracy'])].get('logRe__C'),\n",
    "                               penalty = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_accuracy'])].get('logRe__penalty'),\n",
    "                               solver = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_accuracy'])].get('logRe__solver')\n",
    "                              )\n",
    "    logre.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_acc = accuracy_score(Y_train_arr[i], logre.predict(X_train_arr[i]))\n",
    "    test_acc = accuracy_score(Y_test_arr[i], logre.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_acc)\n",
    "    print(test_acc)\n",
    "    \n",
    "    logre_lam_acc_train.append(train_acc)\n",
    "    logre_lam_acc_test.append(test_acc)\n",
    "    \n",
    "print(logre_lam_acc_train)\n",
    "print(logre_lam_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "honey-passage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79328\n",
      "0.791469329529244\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "logre_lam_acc_train_mean = sum(logre_lam_acc_train)/len(logre_lam_acc_train)\n",
    "logre_lam_acc_test_mean = sum(logre_lam_acc_test)/len(logre_lam_acc_test)\n",
    "print(logre_lam_acc_train_mean)\n",
    "print(logre_lam_acc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-railway",
   "metadata": {},
   "source": [
    "## roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "completed-bridges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7465926453073602\n",
      "0.745267630211297\n",
      "0.7480627907743853\n",
      "0.7487348734873487\n",
      "0.7414691558954254\n",
      "0.7507151830801742\n",
      "0.7437925436832697\n",
      "0.7481143043310416\n",
      "0.7611358387040401\n",
      "0.7409960570093521\n",
      "[0.7465926453073602, 0.7480627907743853, 0.7414691558954254, 0.7437925436832697, 0.7611358387040401]\n",
      "[0.745267630211297, 0.7487348734873487, 0.7507151830801742, 0.7481143043310416, 0.7409960570093521]\n"
     ]
    }
   ],
   "source": [
    "# logre_lam_roc_train stores\n",
    "# logre_lam_roc_test stores\n",
    "logre_lam_roc_train = []\n",
    "logre_lam_roc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    logre = LogisticRegression(max_iter = 7000, \n",
    "                               C = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_roc_auc'])].get('logRe__C'),\n",
    "                               penalty = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_roc_auc'])].get('logRe__penalty'),\n",
    "                               solver = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_roc_auc'])].get('logRe__solver')\n",
    "                              )\n",
    "    logre.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_roc = roc_auc_score(Y_train_arr[i], logre.predict(X_train_arr[i]))\n",
    "    test_roc = roc_auc_score(Y_test_arr[i], logre.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_roc)\n",
    "    print(test_roc)\n",
    "    \n",
    "    logre_lam_roc_train.append(train_roc)\n",
    "    logre_lam_roc_test.append(test_roc)\n",
    "    \n",
    "print(logre_lam_roc_train)\n",
    "print(logre_lam_roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eleven-brave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7482105948728961\n",
      "0.7467656096238426\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "logre_lam_roc_train_mean = sum(logre_lam_roc_train)/len(logre_lam_roc_train)\n",
    "logre_lam_roc_test_mean = sum(logre_lam_roc_test)/len(logre_lam_roc_test)\n",
    "print(logre_lam_roc_train_mean)\n",
    "print(logre_lam_roc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-referral",
   "metadata": {},
   "source": [
    "## f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "massive-interference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8493389510387911\n",
      "0.8485131074500051\n",
      "0.8503776873910518\n",
      "0.8489073881373569\n",
      "0.8446969696969696\n",
      "0.8489433863814245\n",
      "0.8461090061206645\n",
      "0.848960498960499\n",
      "0.8571845368344274\n",
      "0.8448642757045725\n",
      "[0.8493389510387911, 0.8503776873910518, 0.8446969696969696, 0.8461090061206645, 0.8571845368344274]\n",
      "[0.8485131074500051, 0.8489073881373569, 0.8489433863814245, 0.848960498960499, 0.8448642757045725]\n"
     ]
    }
   ],
   "source": [
    "# logre_lam_f1_train stores\n",
    "# logre_lam_f1_test stores\n",
    "logre_lam_f1_train = []\n",
    "logre_lam_f1_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    logre = LogisticRegression(max_iter = 5000, \n",
    "                               C = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_f1'])].get('logRe__C'),\n",
    "                               penalty = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_f1'])].get('logRe__penalty'),\n",
    "                               solver = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_f1'])].get('logRe__solver')\n",
    "                              )\n",
    "    logre.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_f1 = f1_score(Y_train_arr[i], logre.predict(X_train_arr[i]))\n",
    "    test_f1 = f1_score(Y_test_arr[i], logre.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_f1)\n",
    "    print(test_f1)\n",
    "    \n",
    "    logre_lam_f1_train.append(train_f1)\n",
    "    logre_lam_f1_test.append(test_f1)\n",
    "    \n",
    "print(logre_lam_f1_train)\n",
    "print(logre_lam_f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "invisible-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8495414302163808\n",
      "0.8480377313267716\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "logre_lam_f1_train_mean = sum(logre_lam_f1_train)/len(logre_lam_f1_train)\n",
    "logre_lam_f1_test_mean = sum(logre_lam_f1_test)/len(logre_lam_f1_test)\n",
    "print(logre_lam_f1_train_mean)\n",
    "print(logre_lam_f1_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-substance",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "swiss-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C list for SVM\n",
    "C_svm = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]\n",
    "C_svm_linear = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1]\n",
    "\n",
    "# gamma list for SVM with kernel rbf\n",
    "gamma_svm = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "rolled-familiar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##pipe = Pipeline(steps=[('std', StandardScaler()), ('svm_classifier', svm.SVC())])\n",
    "pipe = Pipeline([('svm_classifier', svm.SVC())])\n",
    "\n",
    "search_space = [{'svm_classifier': [svm.SVC()],\n",
    "                 'svm_classifier__kernel': ['linear'],\n",
    "                 'svm_classifier__C': C_svm_linear},\n",
    "                {'svm_classifier': [svm.SVC(max_iter = 1000000)],\n",
    "                 'svm_classifier__kernel': ['linear'],\n",
    "                 'svm_classifier__C': [100, 1000]},\n",
    "                {'svm_classifier': [svm.SVC()],\n",
    "                 'svm_classifier__kernel': ['poly'],\n",
    "                 'svm_classifier__degree': [2, 3],\n",
    "                 'svm_classifier__C': C_svm},\n",
    "                {'svm_classifier': [svm.SVC()],\n",
    "                 'svm_classifier__kernel': ['rbf'],\n",
    "                 'svm_classifier__gamma': gamma_svm,\n",
    "                 'svm_classifier__C': C_svm}\n",
    "                ]\n",
    "\n",
    "clf = GridSearchCV(pipe, search_space, cv = StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc', 'f1'], refit=False,\n",
    "                   verbose=0, n_jobs = -1)\n",
    "\n",
    "best_svm_arr = []\n",
    "\n",
    "#search training set in stratified 5-fold manner cross 5 trials, and store the best models in best_svm_arr\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    best_svm = clf.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    best_svm_arr.append(best_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "needed-candidate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.05, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.1, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.05, 'svm_classifier__kernel': 'rbf'}\n",
      " \n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.05, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.1, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.05, 'svm_classifier__kernel': 'rbf'}\n",
      " \n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.05, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.1, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.05, 'svm_classifier__kernel': 'rbf'}\n",
      " \n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.05, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.1, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.05, 'svm_classifier__kernel': 'rbf'}\n",
      " \n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.05, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.1, 'svm_classifier__kernel': 'rbf'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__gamma': 0.05, 'svm_classifier__kernel': 'rbf'}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#show the result of best models\n",
    "#each group of three is the result for a trial\n",
    "#within each group, each result is the best model for each performance metric\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    print(best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])])\n",
    "    print(best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])])\n",
    "    print(best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])])\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-cocktail",
   "metadata": {},
   "source": [
    "## acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "british-agenda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8798\n",
      "0.8666904422253923\n",
      "0.8776\n",
      "0.8643366619115549\n",
      "0.8682\n",
      "0.8689728958630528\n",
      "0.874\n",
      "0.8661911554921541\n",
      "0.879\n",
      "0.8587018544935806\n",
      "[0.8798, 0.8776, 0.8682, 0.874, 0.879]\n",
      "[0.8666904422253923, 0.8643366619115549, 0.8689728958630528, 0.8661911554921541, 0.8587018544935806]\n"
     ]
    }
   ],
   "source": [
    "# svm_lam_acc_train stores\n",
    "# svm_lam_acc_test stores\n",
    "svm_lam_acc_train = []\n",
    "svm_lam_acc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    if best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__kernel') == 'poly':\n",
    "        svm_cls = svm.SVC(kernel = 'poly',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__C'),\n",
    "                          degree = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__degree')\n",
    "                         )\n",
    "    elif best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__kernel') == 'linear':\n",
    "        svm_cls = svm.SVC(kernel = 'linear',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__C')\n",
    "                         )\n",
    "    else:\n",
    "        svm_cls = svm.SVC(kernel = 'rbf', \n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__C'),\n",
    "                          gamma = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__gamma')\n",
    "                         )\n",
    "    \n",
    "    svm_cls.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_acc = accuracy_score(Y_train_arr[i], svm_cls.predict(X_train_arr[i]))\n",
    "    test_acc = accuracy_score(Y_test_arr[i], svm_cls.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_acc)\n",
    "    print(test_acc)\n",
    "    \n",
    "    svm_lam_acc_train.append(train_acc)\n",
    "    svm_lam_acc_test.append(test_acc)\n",
    "    \n",
    "print(svm_lam_acc_train)\n",
    "print(svm_lam_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "absent-place",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87572\n",
      "0.8649786019971468\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "svm_lam_acc_train_mean = sum(svm_lam_acc_train)/len(svm_lam_acc_train)\n",
    "svm_lam_acc_test_mean = sum(svm_lam_acc_test)/len(svm_lam_acc_test)\n",
    "print(svm_lam_acc_train_mean)\n",
    "print(svm_lam_acc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-canberra",
   "metadata": {},
   "source": [
    "## roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fiscal-transmission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8634270127781065\n",
      "0.8303958387725181\n",
      "0.8533323297252571\n",
      "0.8287731207197799\n",
      "0.8480105750814642\n",
      "0.8323296224145742\n",
      "0.84891189233461\n",
      "0.8297734844478363\n",
      "0.8581333310874969\n",
      "0.8227652481272467\n",
      "[0.8634270127781065, 0.8533323297252571, 0.8480105750814642, 0.84891189233461, 0.8581333310874969]\n",
      "[0.8303958387725181, 0.8287731207197799, 0.8323296224145742, 0.8297734844478363, 0.8227652481272467]\n"
     ]
    }
   ],
   "source": [
    "# svm_lam_roc_train stores\n",
    "# svm_lam_roc_test stores\n",
    "svm_lam_roc_train = []\n",
    "svm_lam_roc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    if best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__kernel') == 'poly':\n",
    "        svm_cls = svm.SVC(kernel = 'poly',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__C'),\n",
    "                          degree = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__degree')\n",
    "                         )\n",
    "    elif best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__kernel') == 'linear':\n",
    "        svm_cls = svm.SVC(kernel = 'linear',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__C')\n",
    "                         )\n",
    "    else:\n",
    "        svm_cls = svm.SVC(kernel = 'rbf', \n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__C'),\n",
    "                          gamma = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__gamma')\n",
    "                         )\n",
    "    \n",
    "    svm_cls.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_roc = roc_auc_score(Y_train_arr[i], svm_cls.predict(X_train_arr[i]))\n",
    "    test_roc = roc_auc_score(Y_test_arr[i], svm_cls.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_roc)\n",
    "    print(test_roc)\n",
    "    \n",
    "    svm_lam_roc_train.append(train_roc)\n",
    "    svm_lam_roc_test.append(test_roc)\n",
    "    \n",
    "print(svm_lam_roc_train)\n",
    "print(svm_lam_roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "administrative-operation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8543630282013869\n",
      "0.8288074628963911\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "svm_lam_roc_train_mean = sum(svm_lam_roc_train)/len(svm_lam_roc_train)\n",
    "svm_lam_roc_test_mean = sum(svm_lam_roc_test)/len(svm_lam_roc_test)\n",
    "print(svm_lam_roc_train_mean)\n",
    "print(svm_lam_roc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-worthy",
   "metadata": {},
   "source": [
    "## f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "legendary-summit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9118639096641736\n",
      "0.9029040469634786\n",
      "0.9107090749927051\n",
      "0.9011331739266036\n",
      "0.9043402525765712\n",
      "0.9045565542681976\n",
      "0.9083236321303843\n",
      "0.9028281363306745\n",
      "0.9119487701935671\n",
      "0.8977759430311162\n",
      "[0.9118639096641736, 0.9107090749927051, 0.9043402525765712, 0.9083236321303843, 0.9119487701935671]\n",
      "[0.9029040469634786, 0.9011331739266036, 0.9045565542681976, 0.9028281363306745, 0.8977759430311162]\n"
     ]
    }
   ],
   "source": [
    "# svm_lam_f1_train stores\n",
    "# svm_lam_f1_test stores\n",
    "svm_lam_f1_train = []\n",
    "svm_lam_f1_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    if best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__kernel') == 'poly':\n",
    "        svm_cls = svm.SVC(kernel = 'poly',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__C'),\n",
    "                          degree = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__degree')\n",
    "                         )\n",
    "    elif best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__kernel') == 'linear':\n",
    "        svm_cls = svm.SVC(kernel = 'linear',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__C')\n",
    "                         )\n",
    "    else:\n",
    "        svm_cls = svm.SVC(kernel = 'rbf', \n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__C'),\n",
    "                          gamma = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__gamma')\n",
    "                         )\n",
    "    \n",
    "    svm_cls.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_f1 = f1_score(Y_train_arr[i], svm_cls.predict(X_train_arr[i]))\n",
    "    test_f1 = f1_score(Y_test_arr[i], svm_cls.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_f1)\n",
    "    print(test_f1)\n",
    "    \n",
    "    svm_lam_f1_train.append(train_f1)\n",
    "    svm_lam_f1_test.append(test_f1)\n",
    "    \n",
    "print(svm_lam_f1_train)\n",
    "print(svm_lam_f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "manufactured-calibration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9094371279114803\n",
      "0.9018395709040142\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "svm_lam_f1_train_mean = sum(svm_lam_f1_train)/len(svm_lam_f1_train)\n",
    "svm_lam_f1_test_mean = sum(svm_lam_f1_test)/len(svm_lam_f1_test)\n",
    "print(svm_lam_f1_train_mean)\n",
    "print(svm_lam_f1_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-consolidation",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "later-converter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   5,   9,  13,  17,  21,  25,  29,  33,  37,  41,  45,  49,\n",
       "        53,  57,  61,  65,  69,  73,  77,  81,  85,  89,  93,  97, 101])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K list for KNN\n",
    "K_knn = np.arange(1, 105, 4)\n",
    "K_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adopted-timing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##pipe = Pipeline(steps=[('std', StandardScaler()), ('knn', KNeighborsClassifier())])\n",
    "pipe = Pipeline([('knn', KNeighborsClassifier())])\n",
    "\n",
    "search_space = [{'knn': [KNeighborsClassifier()],\n",
    "                 'knn__weights': ['uniform', 'distance'],\n",
    "                 'knn__n_neighbors': K_knn}\n",
    "                ]\n",
    "\n",
    "search = GridSearchCV(pipe, search_space, cv = StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc', 'f1'], refit=False,\n",
    "                   verbose=0, n_jobs = -1)\n",
    "\n",
    "best_knn_arr = []\n",
    "\n",
    "#search training set in stratified 5-fold manner cross 5 trials, and store the best models in best_svm_arr\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    best_knn = search.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    best_knn_arr.append(best_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adjusted-cheese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 13, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 25, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 13, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 13, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 25, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 13, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 13, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 25, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 13, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 13, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 25, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 13, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 13, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 25, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 13, 'knn__weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "#show the result of best models\n",
    "#each group of three is the result for a trial\n",
    "#within each group, each result is the best model for each performance metric\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    print(best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_accuracy'])])\n",
    "    print(best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_roc_auc'])])\n",
    "    print(best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_f1'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-polls",
   "metadata": {},
   "source": [
    "## acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "immune-dubai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8314550641940086\n",
      "1.0\n",
      "0.8310271041369472\n",
      "1.0\n",
      "0.8323823109843081\n",
      "1.0\n",
      "0.8294579172610557\n",
      "1.0\n",
      "0.8278174037089872\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.8314550641940086, 0.8310271041369472, 0.8323823109843081, 0.8294579172610557, 0.8278174037089872]\n"
     ]
    }
   ],
   "source": [
    "# knn_lam_acc_train stores\n",
    "# knn_lam_acc_test stores\n",
    "knn_lam_acc_train = []\n",
    "knn_lam_acc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    knn = KNeighborsClassifier(weights = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_accuracy'])].get('knn__weights'),\n",
    "                               n_neighbors = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_accuracy'])].get('knn__n_neighbors')\n",
    "                              )\n",
    "    knn.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_acc = accuracy_score(Y_train_arr[i], knn.predict(X_train_arr[i]))\n",
    "    test_acc = accuracy_score(Y_test_arr[i], knn.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_acc)\n",
    "    print(test_acc)\n",
    "    \n",
    "    knn_lam_acc_train.append(train_acc)\n",
    "    knn_lam_acc_test.append(test_acc)\n",
    "    \n",
    "print(knn_lam_acc_train)\n",
    "print(knn_lam_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "south-eagle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8304279600570613\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "knn_lam_acc_train_mean = sum(knn_lam_acc_train)/len(knn_lam_acc_train)\n",
    "knn_lam_acc_test_mean = sum(knn_lam_acc_test)/len(knn_lam_acc_test)\n",
    "print(knn_lam_acc_train_mean)\n",
    "print(knn_lam_acc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-bumper",
   "metadata": {},
   "source": [
    "## roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "similar-imperial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.770040523322109\n",
      "1.0\n",
      "0.7700215559081263\n",
      "1.0\n",
      "0.7718644075360883\n",
      "1.0\n",
      "0.7631370540705186\n",
      "1.0\n",
      "0.7594636238471717\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.770040523322109, 0.7700215559081263, 0.7718644075360883, 0.7631370540705186, 0.7594636238471717]\n"
     ]
    }
   ],
   "source": [
    "# knn_lam_roc_train stores\n",
    "# knn_lam_roc_test stores\n",
    "knn_lam_roc_train = []\n",
    "knn_lam_roc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    knn = KNeighborsClassifier(weights = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_roc_auc'])].get('knn__weights'),\n",
    "                               n_neighbors = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_roc_auc'])].get('knn__n_neighbors')\n",
    "                              )\n",
    "    knn.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_roc = roc_auc_score(Y_train_arr[i], knn.predict(X_train_arr[i]))\n",
    "    test_roc = roc_auc_score(Y_test_arr[i], knn.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_roc)\n",
    "    print(test_roc)\n",
    "    \n",
    "    knn_lam_roc_train.append(train_roc)\n",
    "    knn_lam_roc_test.append(test_roc)\n",
    "    \n",
    "print(knn_lam_roc_train)\n",
    "print(knn_lam_roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "renewable-constant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7669054329368029\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "knn_lam_roc_train_mean = sum(knn_lam_roc_train)/len(knn_lam_roc_train)\n",
    "knn_lam_roc_test_mean = sum(knn_lam_roc_test)/len(knn_lam_roc_test)\n",
    "print(knn_lam_roc_train_mean)\n",
    "print(knn_lam_roc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-empty",
   "metadata": {},
   "source": [
    "## f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "lined-seller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.880541934179263\n",
      "1.0\n",
      "0.8802386128102726\n",
      "1.0\n",
      "0.8807953738459977\n",
      "1.0\n",
      "0.8791630868752212\n",
      "1.0\n",
      "0.8785347690449834\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.880541934179263, 0.8802386128102726, 0.8807953738459977, 0.8791630868752212, 0.8785347690449834]\n"
     ]
    }
   ],
   "source": [
    "# knn_lam_f1_train stores\n",
    "# knn_lam_f1_test stores\n",
    "knn_lam_f1_train = []\n",
    "knn_lam_f1_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    knn = KNeighborsClassifier(weights = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_f1'])].get('knn__weights'),\n",
    "                               n_neighbors = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_f1'])].get('knn__n_neighbors')\n",
    "                              )\n",
    "    knn.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_f1 = f1_score(Y_train_arr[i], knn.predict(X_train_arr[i]))\n",
    "    test_f1 = f1_score(Y_test_arr[i], knn.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_f1)\n",
    "    print(test_f1)\n",
    "    \n",
    "    knn_lam_f1_train.append(train_f1)\n",
    "    knn_lam_f1_test.append(test_f1)\n",
    "    \n",
    "print(knn_lam_f1_train)\n",
    "print(knn_lam_f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fancy-teddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8798547553511475\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "knn_lam_f1_train_mean = sum(knn_lam_f1_train)/len(knn_lam_f1_train)\n",
    "knn_lam_f1_test_mean = sum(knn_lam_f1_test)/len(knn_lam_f1_test)\n",
    "print(knn_lam_f1_train_mean)\n",
    "print(knn_lam_f1_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-helicopter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
