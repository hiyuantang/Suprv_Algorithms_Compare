{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thrown-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-freedom",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "obvious-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', \n",
    "                'education-num', 'marital-status', 'occupation', \n",
    "                'relationship', 'race', 'sex', 'capital-gain', \n",
    "                'capital-loss', 'hours-per-week' ,'native-country' ,'Y']\n",
    "## df_adult = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names = column_names, index_col = False)\n",
    "df_adult = pd.read_csv('adult.data', names = column_names, index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "native-option",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country       Y  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_adult.shape)\n",
    "df_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "shaped-nitrogen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education-num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0         Male          2174             0              40   United-States  \n",
       "1         Male             0             0              13   United-States  \n",
       "2         Male             0             0              40   United-States  \n",
       "3         Male             0             0              40   United-States  \n",
       "4       Female             0             0              40            Cuba  \n",
       "...        ...           ...           ...             ...             ...  \n",
       "32556   Female             0             0              38   United-States  \n",
       "32557     Male             0             0              40   United-States  \n",
       "32558   Female             0             0              40   United-States  \n",
       "32559     Male             0             0              20   United-States  \n",
       "32560   Female         15024             0              40   United-States  \n",
       "\n",
       "[32561 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_adult.iloc[:, :14]\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ranking-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = make_column_transformer(\n",
    "    (OneHotEncoder(), ['workclass', 'education', 'marital-status', \n",
    "                       'occupation', 'relationship' ,'race', 'sex', \n",
    "                       'native-country']), \n",
    "    remainder = 'passthrough')\n",
    "X_t = trans.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wrong-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X_t, columns = np.arange(0, 108, 1))\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minus-pride",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.240810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.427581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Y\n",
       "count  32561.000000\n",
       "mean       0.240810\n",
       "std        0.427581\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df_adult.loc[:, ['Y']]\n",
    "Y = Y.replace(' <=50K', 0)\n",
    "Y = Y.replace(' >50K', 1)\n",
    "Y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alike-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat training and testing data sets for 5 trials\n",
    "X_train_arr = []\n",
    "X_test_arr = []\n",
    "Y_train_arr = []\n",
    "Y_test_arr = []\n",
    "\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split( \n",
    "        X, Y, train_size = 5000, stratify = Y, \n",
    "        shuffle = True, random_state = i)\n",
    "    X_train_arr.append(X_train)\n",
    "    X_test_arr.append(X_test)\n",
    "    Y_train_arr.append(Y_train)\n",
    "    Y_test_arr.append(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "painful-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0, 1, 2, 3, 4]:\n",
    "    Y_train_arr[i] = Y_train_arr[i].values.ravel()\n",
    "    Y_test_arr[i] = Y_test_arr[i].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-nickname",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sufficient-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_list for SVM.\n",
    "C_logre = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, \n",
    "         1e1, 1e2, 1e3, 1e4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "handled-supplement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([('logRe', LogisticRegression())])\n",
    "\n",
    "search_space = [{'logRe': [LogisticRegression(max_iter = 5000)],\n",
    "                 'logRe__solver': ['saga'],\n",
    "                 'logRe__penalty': ['l1', 'l2'],\n",
    "                 'logRe__C': C_logre},\n",
    "                {'logRe': [LogisticRegression(max_iter = 5000)],\n",
    "                 'logRe__solver': ['lbfgs', 'sag', 'newton-cg'],\n",
    "                 'logRe__penalty': ['l2'],\n",
    "                 'logRe__C': C_logre},\n",
    "                {'logRe': [LogisticRegression(max_iter = 5000)],\n",
    "                 'logRe__solver': ['saga', 'lbfgs', 'sag', 'newton-cg'],\n",
    "                 'logRe__penalty': ['none']}\n",
    "                ]\n",
    "\n",
    "search = GridSearchCV(pipe, search_space, cv = StratifiedKFold(n_splits=5), \n",
    "                   scoring = ['accuracy', 'roc_auc', 'f1'], refit = False,\n",
    "                   verbose = 0, n_jobs = -1)\n",
    "\n",
    "best_logre_arr = []\n",
    "\n",
    "#search training set in stratified 5-fold manner cross 5 trials, and store the best models in best_logre_arr\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    best_logre = search.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    best_logre_arr.append(best_logre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "correct-insured",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l2', 'logRe__solver': 'newton-cg'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 0.1, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l2', 'logRe__solver': 'sag'}\n",
      " \n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l2', 'logRe__solver': 'newton-cg'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 0.1, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l2', 'logRe__solver': 'sag'}\n",
      " \n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l2', 'logRe__solver': 'newton-cg'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 0.1, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l2', 'logRe__solver': 'sag'}\n",
      " \n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l2', 'logRe__solver': 'newton-cg'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 0.1, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l2', 'logRe__solver': 'sag'}\n",
      " \n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l2', 'logRe__solver': 'newton-cg'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 0.1, 'logRe__penalty': 'l1', 'logRe__solver': 'saga'}\n",
      "{'logRe': LogisticRegression(max_iter=5000), 'logRe__C': 10.0, 'logRe__penalty': 'l2', 'logRe__solver': 'sag'}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#show the result of best models\n",
    "#each group of three is the result for a trial\n",
    "#within each group, each result is the best model for each performance metric\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    print(best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_accuracy'])])\n",
    "    print(best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_roc_auc'])])\n",
    "    print(best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_f1'])])\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-mumbai",
   "metadata": {},
   "source": [
    "## acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "explicit-interstate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8556\n",
      "0.8483727005551323\n",
      "0.856\n",
      "0.8471390733282537\n",
      "0.8488\n",
      "0.849715177243206\n",
      "0.8518\n",
      "0.8480461521715468\n",
      "0.8574\n",
      "0.8475744711730343\n",
      "[0.8556, 0.856, 0.8488, 0.8518, 0.8574]\n",
      "[0.8483727005551323, 0.8471390733282537, 0.849715177243206, 0.8480461521715468, 0.8475744711730343]\n"
     ]
    }
   ],
   "source": [
    "# logre_lam_acc_train \n",
    "# logre_lam_acc_test \n",
    "logre_lam_acc_train = []\n",
    "logre_lam_acc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    logre = LogisticRegression(max_iter = 5000, \n",
    "                               C = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_accuracy'])].get('logRe__C'),\n",
    "                               penalty = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_accuracy'])].get('logRe__penalty'),\n",
    "                               solver = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_accuracy'])].get('logRe__solver')\n",
    "                              )\n",
    "    logre.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_acc = accuracy_score(Y_train_arr[i], logre.predict(X_train_arr[i]))\n",
    "    test_acc = accuracy_score(Y_test_arr[i], logre.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_acc)\n",
    "    print(test_acc)\n",
    "    \n",
    "    logre_lam_acc_train.append(train_acc)\n",
    "    logre_lam_acc_test.append(test_acc)\n",
    "    \n",
    "print(logre_lam_acc_train)\n",
    "print(logre_lam_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "honey-passage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8539199999999999\n",
      "0.8481695148942346\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "logre_lam_acc_train_mean = sum(logre_lam_acc_train)/len(logre_lam_acc_train)\n",
    "logre_lam_acc_test_mean = sum(logre_lam_acc_test)/len(logre_lam_acc_test)\n",
    "print(logre_lam_acc_train_mean)\n",
    "print(logre_lam_acc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-railway",
   "metadata": {},
   "source": [
    "## roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "completed-bridges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7665404044824243\n",
      "0.7627082999274124\n",
      "0.7671880524699893\n",
      "0.7593563209177033\n",
      "0.7566541454722404\n",
      "0.7603375692832915\n",
      "0.7609386869899774\n",
      "0.7617269291474571\n",
      "0.7724147467696368\n",
      "0.7612036077271059\n",
      "[0.7665404044824243, 0.7671880524699893, 0.7566541454722404, 0.7609386869899774, 0.7724147467696368]\n",
      "[0.7627082999274124, 0.7593563209177033, 0.7603375692832915, 0.7617269291474571, 0.7612036077271059]\n"
     ]
    }
   ],
   "source": [
    "# logre_lam_roc_train stores\n",
    "# logre_lam_roc_test stores\n",
    "logre_lam_roc_train = []\n",
    "logre_lam_roc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    logre = LogisticRegression(max_iter = 7000, \n",
    "                               C = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_roc_auc'])].get('logRe__C'),\n",
    "                               penalty = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_roc_auc'])].get('logRe__penalty'),\n",
    "                               solver = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_roc_auc'])].get('logRe__solver')\n",
    "                              )\n",
    "    logre.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_roc = roc_auc_score(Y_train_arr[i], logre.predict(X_train_arr[i]))\n",
    "    test_roc = roc_auc_score(Y_test_arr[i], logre.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_roc)\n",
    "    print(test_roc)\n",
    "    \n",
    "    logre_lam_roc_train.append(train_roc)\n",
    "    logre_lam_roc_test.append(test_roc)\n",
    "    \n",
    "print(logre_lam_roc_train)\n",
    "print(logre_lam_roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eleven-brave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7647472072368536\n",
      "0.761066545400594\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "logre_lam_roc_train_mean = sum(logre_lam_roc_train)/len(logre_lam_roc_train)\n",
    "logre_lam_roc_test_mean = sum(logre_lam_roc_test)/len(logre_lam_roc_test)\n",
    "print(logre_lam_roc_train_mean)\n",
    "print(logre_lam_roc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-referral",
   "metadata": {},
   "source": [
    "## f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "massive-interference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6721162579473207\n",
      "0.6565349544072948\n",
      "0.6739130434782609\n",
      "0.6567334310372903\n",
      "0.6566757493188011\n",
      "0.6547787684359637\n",
      "0.6617915904936014\n",
      "0.6569558101472994\n",
      "0.6801437556154538\n",
      "0.6548919740409102\n",
      "[0.6721162579473207, 0.6739130434782609, 0.6566757493188011, 0.6617915904936014, 0.6801437556154538]\n",
      "[0.6565349544072948, 0.6567334310372903, 0.6547787684359637, 0.6569558101472994, 0.6548919740409102]\n"
     ]
    }
   ],
   "source": [
    "# logre_lam_f1_train stores\n",
    "# logre_lam_f1_test stores\n",
    "logre_lam_f1_train = []\n",
    "logre_lam_f1_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    logre = LogisticRegression(max_iter = 5000, \n",
    "                               C = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_f1'])].get('logRe__C'),\n",
    "                               penalty = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_f1'])].get('logRe__penalty'),\n",
    "                               solver = best_logre_arr[i].cv_results_['params'][np.argmin(best_logre_arr[i].cv_results_['rank_test_f1'])].get('logRe__solver')\n",
    "                              )\n",
    "    logre.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_f1 = f1_score(Y_train_arr[i], logre.predict(X_train_arr[i]))\n",
    "    test_f1 = f1_score(Y_test_arr[i], logre.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_f1)\n",
    "    print(test_f1)\n",
    "    \n",
    "    logre_lam_f1_train.append(train_f1)\n",
    "    logre_lam_f1_test.append(test_f1)\n",
    "    \n",
    "print(logre_lam_f1_train)\n",
    "print(logre_lam_f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "invisible-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6689280793706877\n",
      "0.6559789876137516\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "logre_lam_f1_train_mean = sum(logre_lam_f1_train)/len(logre_lam_f1_train)\n",
    "logre_lam_f1_test_mean = sum(logre_lam_f1_test)/len(logre_lam_f1_test)\n",
    "print(logre_lam_f1_train_mean)\n",
    "print(logre_lam_f1_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-substance",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "swiss-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C list for SVM\n",
    "C_svm = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]\n",
    "C_svm_linear = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1]\n",
    "\n",
    "# gamma list for SVM with kernel rbf\n",
    "gamma_svm = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rolled-familiar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##pipe = Pipeline(steps=[('std', StandardScaler()), ('svm_classifier', svm.SVC())])\n",
    "pipe = Pipeline([('svm_classifier', svm.SVC())])\n",
    "\n",
    "search_space = [{'svm_classifier': [svm.SVC()],\n",
    "                 'svm_classifier__kernel': ['linear'],\n",
    "                 'svm_classifier__C': C_svm_linear},\n",
    "                {'svm_classifier': [svm.SVC(max_iter = 1000000)],\n",
    "                 'svm_classifier__kernel': ['linear'],\n",
    "                 'svm_classifier__C': [100, 1000]},\n",
    "                {'svm_classifier': [svm.SVC()],\n",
    "                 'svm_classifier__kernel': ['poly'],\n",
    "                 'svm_classifier__degree': [2, 3],\n",
    "                 'svm_classifier__C': C_svm},\n",
    "                {'svm_classifier': [svm.SVC()],\n",
    "                 'svm_classifier__kernel': ['rbf'],\n",
    "                 'svm_classifier__gamma': gamma_svm,\n",
    "                 'svm_classifier__C': C_svm}\n",
    "                ]\n",
    "\n",
    "clf = GridSearchCV(pipe, search_space, cv = StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc', 'f1'], refit=False,\n",
    "                   verbose=0, n_jobs = -1)\n",
    "\n",
    "best_svm_arr = []\n",
    "\n",
    "#search training set in stratified 5-fold manner cross 5 trials, and store the best models in best_svm_arr\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    best_svm = clf.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    best_svm_arr.append(best_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "needed-candidate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__kernel': 'linear'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 0.1, 'svm_classifier__kernel': 'linear'}\n",
      "{'svm_classifier': SVC(max_iter=1000000), 'svm_classifier__C': 100, 'svm_classifier__kernel': 'linear'}\n",
      " \n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__kernel': 'linear'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 0.1, 'svm_classifier__kernel': 'linear'}\n",
      "{'svm_classifier': SVC(max_iter=1000000), 'svm_classifier__C': 100, 'svm_classifier__kernel': 'linear'}\n",
      " \n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__kernel': 'linear'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 0.1, 'svm_classifier__kernel': 'linear'}\n",
      "{'svm_classifier': SVC(max_iter=1000000), 'svm_classifier__C': 100, 'svm_classifier__kernel': 'linear'}\n",
      " \n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__kernel': 'linear'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 0.1, 'svm_classifier__kernel': 'linear'}\n",
      "{'svm_classifier': SVC(max_iter=1000000), 'svm_classifier__C': 100, 'svm_classifier__kernel': 'linear'}\n",
      " \n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 10.0, 'svm_classifier__kernel': 'linear'}\n",
      "{'svm_classifier': SVC(), 'svm_classifier__C': 0.1, 'svm_classifier__kernel': 'linear'}\n",
      "{'svm_classifier': SVC(max_iter=1000000), 'svm_classifier__C': 100, 'svm_classifier__kernel': 'linear'}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#show the result of best models\n",
    "#each group of three is the result for a trial\n",
    "#within each group, each result is the best model for each performance metric\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    print(best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])])\n",
    "    print(best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])])\n",
    "    print(best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])])\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-cocktail",
   "metadata": {},
   "source": [
    "## acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "british-agenda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8542\n",
      "0.8490983636297667\n",
      "0.8602\n",
      "0.8481550016327419\n",
      "0.8492\n",
      "0.8515293349297921\n",
      "0.8546\n",
      "0.8492072130909619\n",
      "0.8556\n",
      "0.8495700446282791\n",
      "[0.8542, 0.8602, 0.8492, 0.8546, 0.8556]\n",
      "[0.8490983636297667, 0.8481550016327419, 0.8515293349297921, 0.8492072130909619, 0.8495700446282791]\n"
     ]
    }
   ],
   "source": [
    "# svm_lam_acc_train stores\n",
    "# svm_lam_acc_test stores\n",
    "svm_lam_acc_train = []\n",
    "svm_lam_acc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    if best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__kernel') == 'poly':\n",
    "        svm_cls = svm.SVC(kernel = 'poly',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__C'),\n",
    "                          degree = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__degree')\n",
    "                         )\n",
    "    elif best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__kernel') == 'linear':\n",
    "        svm_cls = svm.SVC(kernel = 'linear',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__C')\n",
    "                         )\n",
    "    else:\n",
    "        svm_cls = svm.SVC(kernel = 'rbf', \n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__C'),\n",
    "                          gamma = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_accuracy'])].get('svm_classifier__gamma')\n",
    "                         )\n",
    "    \n",
    "    svm_cls.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_acc = accuracy_score(Y_train_arr[i], svm_cls.predict(X_train_arr[i]))\n",
    "    test_acc = accuracy_score(Y_test_arr[i], svm_cls.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_acc)\n",
    "    print(test_acc)\n",
    "    \n",
    "    svm_lam_acc_train.append(train_acc)\n",
    "    svm_lam_acc_test.append(test_acc)\n",
    "    \n",
    "print(svm_lam_acc_train)\n",
    "print(svm_lam_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "absent-place",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8547600000000001\n",
      "0.8495119915823084\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "svm_lam_acc_train_mean = sum(svm_lam_acc_train)/len(svm_lam_acc_train)\n",
    "svm_lam_acc_test_mean = sum(svm_lam_acc_test)/len(svm_lam_acc_test)\n",
    "print(svm_lam_acc_train_mean)\n",
    "print(svm_lam_acc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-canberra",
   "metadata": {},
   "source": [
    "## roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fiscal-transmission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7657299692979846\n",
      "0.7619602293290596\n",
      "0.7798587602267119\n",
      "0.7685679696557538\n",
      "0.7582951454407333\n",
      "0.757094506656706\n",
      "0.7645554509205353\n",
      "0.7591715688340165\n",
      "0.7717762883818953\n",
      "0.7623883447754282\n",
      "[0.7657299692979846, 0.7798587602267119, 0.7582951454407333, 0.7645554509205353, 0.7717762883818953]\n",
      "[0.7619602293290596, 0.7685679696557538, 0.757094506656706, 0.7591715688340165, 0.7623883447754282]\n"
     ]
    }
   ],
   "source": [
    "# svm_lam_roc_train stores\n",
    "# svm_lam_roc_test stores\n",
    "svm_lam_roc_train = []\n",
    "svm_lam_roc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    if best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__kernel') == 'poly':\n",
    "        svm_cls = svm.SVC(kernel = 'poly',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__C'),\n",
    "                          degree = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__degree')\n",
    "                         )\n",
    "    elif best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__kernel') == 'linear':\n",
    "        svm_cls = svm.SVC(kernel = 'linear',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__C')\n",
    "                         )\n",
    "    else:\n",
    "        svm_cls = svm.SVC(kernel = 'rbf', \n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__C'),\n",
    "                          gamma = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_roc_auc'])].get('svm_classifier__gamma')\n",
    "                         )\n",
    "    \n",
    "    svm_cls.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_roc = roc_auc_score(Y_train_arr[i], svm_cls.predict(X_train_arr[i]))\n",
    "    test_roc = roc_auc_score(Y_test_arr[i], svm_cls.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_roc)\n",
    "    print(test_roc)\n",
    "    \n",
    "    svm_lam_roc_train.append(train_roc)\n",
    "    svm_lam_roc_test.append(test_roc)\n",
    "    \n",
    "print(svm_lam_roc_train)\n",
    "print(svm_lam_roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "administrative-operation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.768043122853572\n",
      "0.7618365238501928\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "svm_lam_roc_train_mean = sum(svm_lam_roc_train)/len(svm_lam_roc_train)\n",
    "svm_lam_roc_test_mean = sum(svm_lam_roc_test)/len(svm_lam_roc_test)\n",
    "print(svm_lam_roc_train_mean)\n",
    "print(svm_lam_roc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-worthy",
   "metadata": {},
   "source": [
    "## f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "legendary-summit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6629732225300092\n",
      "0.6551152379373238\n",
      "0.6861248316120341\n",
      "0.6617658938524921\n",
      "0.6509040333796939\n",
      "0.6526905448989985\n",
      "0.6632653061224489\n",
      "0.653316645807259\n",
      "0.6727107887579329\n",
      "0.6580400560454958\n",
      "[0.6629732225300092, 0.6861248316120341, 0.6509040333796939, 0.6632653061224489, 0.6727107887579329]\n",
      "[0.6551152379373238, 0.6617658938524921, 0.6526905448989985, 0.653316645807259, 0.6580400560454958]\n"
     ]
    }
   ],
   "source": [
    "# svm_lam_f1_train stores\n",
    "# svm_lam_f1_test stores\n",
    "svm_lam_f1_train = []\n",
    "svm_lam_f1_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    if best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__kernel') == 'poly':\n",
    "        svm_cls = svm.SVC(kernel = 'poly',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__C'),\n",
    "                          degree = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__degree')\n",
    "                         )\n",
    "    elif best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__kernel') == 'linear':\n",
    "        svm_cls = svm.SVC(kernel = 'linear',\n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__C')\n",
    "                         )\n",
    "    else:\n",
    "        svm_cls = svm.SVC(kernel = 'rbf', \n",
    "                          C = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__C'),\n",
    "                          gamma = best_svm_arr[i].cv_results_['params'][np.argmin(best_svm_arr[i].cv_results_['rank_test_f1'])].get('svm_classifier__gamma')\n",
    "                         )\n",
    "    \n",
    "    svm_cls.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_f1 = f1_score(Y_train_arr[i], svm_cls.predict(X_train_arr[i]))\n",
    "    test_f1 = f1_score(Y_test_arr[i], svm_cls.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_f1)\n",
    "    print(test_f1)\n",
    "    \n",
    "    svm_lam_f1_train.append(train_f1)\n",
    "    svm_lam_f1_test.append(test_f1)\n",
    "    \n",
    "print(svm_lam_f1_train)\n",
    "print(svm_lam_f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "manufactured-calibration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6671956364804238\n",
      "0.6561856757083138\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "svm_lam_f1_train_mean = sum(svm_lam_f1_train)/len(svm_lam_f1_train)\n",
    "svm_lam_f1_test_mean = sum(svm_lam_f1_test)/len(svm_lam_f1_test)\n",
    "print(svm_lam_f1_train_mean)\n",
    "print(svm_lam_f1_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-consolidation",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "later-converter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   5,   9,  13,  17,  21,  25,  29,  33,  37,  41,  45,  49,\n",
       "        53,  57,  61,  65,  69,  73,  77,  81,  85,  89,  93,  97, 101])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K list for KNN\n",
    "K_knn = np.arange(1, 105, 4)\n",
    "K_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adopted-timing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##pipe = Pipeline(steps=[('std', StandardScaler()), ('knn', KNeighborsClassifier())])\n",
    "pipe = Pipeline([('knn', KNeighborsClassifier())])\n",
    "\n",
    "search_space = [{'knn': [KNeighborsClassifier()],\n",
    "                 'knn__weights': ['uniform', 'distance'],\n",
    "                 'knn__n_neighbors': K_knn}\n",
    "                ]\n",
    "\n",
    "search = GridSearchCV(pipe, search_space, cv = StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc', 'f1'], refit=False,\n",
    "                   verbose=0, n_jobs = -1)\n",
    "\n",
    "best_knn_arr = []\n",
    "\n",
    "#search training set in stratified 5-fold manner cross 5 trials, and store the best models in best_svm_arr\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    best_knn = search.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    best_knn_arr.append(best_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adjusted-cheese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 93, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 101, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 21, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 93, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 101, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 21, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 93, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 101, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 21, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 93, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 101, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 21, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 93, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 101, 'knn__weights': 'distance'}\n",
      "{'knn': KNeighborsClassifier(), 'knn__n_neighbors': 21, 'knn__weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "#show the result of best models\n",
    "#each group of three is the result for a trial\n",
    "#within each group, each result is the best model for each performance metric\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    print(best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_accuracy'])])\n",
    "    print(best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_roc_auc'])])\n",
    "    print(best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_f1'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-polls",
   "metadata": {},
   "source": [
    "## acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "immune-dubai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8307028046877835\n",
      "1.0\n",
      "0.8274736040056602\n",
      "1.0\n",
      "0.8318638656071986\n",
      "1.0\n",
      "0.8309567867639055\n",
      "1.0\n",
      "0.8295417437683683\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.8307028046877835, 0.8274736040056602, 0.8318638656071986, 0.8309567867639055, 0.8295417437683683]\n"
     ]
    }
   ],
   "source": [
    "# knn_lam_acc_train stores\n",
    "# knn_lam_acc_test stores\n",
    "knn_lam_acc_train = []\n",
    "knn_lam_acc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    knn = KNeighborsClassifier(weights = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_accuracy'])].get('knn__weights'),\n",
    "                               n_neighbors = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_accuracy'])].get('knn__n_neighbors')\n",
    "                              )\n",
    "    knn.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_acc = accuracy_score(Y_train_arr[i], knn.predict(X_train_arr[i]))\n",
    "    test_acc = accuracy_score(Y_test_arr[i], knn.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_acc)\n",
    "    print(test_acc)\n",
    "    \n",
    "    knn_lam_acc_train.append(train_acc)\n",
    "    knn_lam_acc_test.append(test_acc)\n",
    "    \n",
    "print(knn_lam_acc_train)\n",
    "print(knn_lam_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "south-eagle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8301077609665832\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "knn_lam_acc_train_mean = sum(knn_lam_acc_train)/len(knn_lam_acc_train)\n",
    "knn_lam_acc_test_mean = sum(knn_lam_acc_test)/len(knn_lam_acc_test)\n",
    "print(knn_lam_acc_train_mean)\n",
    "print(knn_lam_acc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-bumper",
   "metadata": {},
   "source": [
    "## roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "similar-imperial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.710927713826432\n",
      "1.0\n",
      "0.711449901113674\n",
      "1.0\n",
      "0.7192904261278691\n",
      "1.0\n",
      "0.717959922371433\n",
      "1.0\n",
      "0.7233148848641028\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.710927713826432, 0.711449901113674, 0.7192904261278691, 0.717959922371433, 0.7233148848641028]\n"
     ]
    }
   ],
   "source": [
    "# knn_lam_roc_train stores\n",
    "# knn_lam_roc_test stores\n",
    "knn_lam_roc_train = []\n",
    "knn_lam_roc_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    knn = KNeighborsClassifier(weights = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_roc_auc'])].get('knn__weights'),\n",
    "                               n_neighbors = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_roc_auc'])].get('knn__n_neighbors')\n",
    "                              )\n",
    "    knn.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_roc = roc_auc_score(Y_train_arr[i], knn.predict(X_train_arr[i]))\n",
    "    test_roc = roc_auc_score(Y_test_arr[i], knn.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_roc)\n",
    "    print(test_roc)\n",
    "    \n",
    "    knn_lam_roc_train.append(train_roc)\n",
    "    knn_lam_roc_test.append(test_roc)\n",
    "    \n",
    "print(knn_lam_roc_train)\n",
    "print(knn_lam_roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "renewable-constant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7165885696607022\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "knn_lam_roc_train_mean = sum(knn_lam_roc_train)/len(knn_lam_roc_train)\n",
    "knn_lam_roc_test_mean = sum(knn_lam_roc_test)/len(knn_lam_roc_test)\n",
    "print(knn_lam_roc_train_mean)\n",
    "print(knn_lam_roc_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-empty",
   "metadata": {},
   "source": [
    "## f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "lined-seller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.5867428379400151\n",
      "1.0\n",
      "0.5854895991882293\n",
      "1.0\n",
      "0.5878081729145558\n",
      "1.0\n",
      "0.6048098527086627\n",
      "1.0\n",
      "0.597335121092768\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.5867428379400151, 0.5854895991882293, 0.5878081729145558, 0.6048098527086627, 0.597335121092768]\n"
     ]
    }
   ],
   "source": [
    "# knn_lam_f1_train stores\n",
    "# knn_lam_f1_test stores\n",
    "knn_lam_f1_train = []\n",
    "knn_lam_f1_test = []\n",
    "\n",
    "#calculate the training and testing performance looping through each trial\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    knn = KNeighborsClassifier(weights = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_f1'])].get('knn__weights'),\n",
    "                               n_neighbors = best_knn_arr[i].cv_results_['params'][np.argmin(best_knn_arr[i].cv_results_['rank_test_f1'])].get('knn__n_neighbors')\n",
    "                              )\n",
    "    knn.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    \n",
    "    train_f1 = f1_score(Y_train_arr[i], knn.predict(X_train_arr[i]))\n",
    "    test_f1 = f1_score(Y_test_arr[i], knn.predict(X_test_arr[i]))\n",
    "    \n",
    "    print(train_f1)\n",
    "    print(test_f1)\n",
    "    \n",
    "    knn_lam_f1_train.append(train_f1)\n",
    "    knn_lam_f1_test.append(test_f1)\n",
    "    \n",
    "print(knn_lam_f1_train)\n",
    "print(knn_lam_f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fancy-teddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.5924371167688463\n"
     ]
    }
   ],
   "source": [
    "#get the mean scores cross 5 trials for each algo/dataset combo\n",
    "knn_lam_f1_train_mean = sum(knn_lam_f1_train)/len(knn_lam_f1_train)\n",
    "knn_lam_f1_test_mean = sum(knn_lam_f1_test)/len(knn_lam_f1_test)\n",
    "print(knn_lam_f1_train_mean)\n",
    "print(knn_lam_f1_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-helicopter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
